{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e966a723",
   "metadata": {},
   "source": [
    "# Original: https://github.com/benmoseley/harmonic-oscillator-pinn\n",
    "\n",
    "# pendulum physics-informed neural network (PINN)\n",
    "\n",
    "\n",
    "## Problem overview\n",
    "\n",
    "The example problem we solve here is the 2D damped pendulum:\n",
    "$$\n",
    "\\ddot \\theta + \\frac{\\delta}{m \\ell^2} \\cdot \\dot \\theta + \\frac{g}{\\ell} \\cdot \\sin(\\theta)  = 0~,\n",
    "$$\n",
    "with the initial conditions\n",
    "$$\n",
    "\\theta(0) = 3.14~[rad]~~,~~\\dot \\theta(0) = 0~[\\frac{rad}{s}]~.\n",
    "$$\n",
    "This has the following exact solution:\n",
    "$$\n",
    "???\n",
    "$$\n",
    "\n",
    "## Workflow overview\n",
    "\n",
    ">First we will train a standard neural network to interpolate a small part of the solution, using some observed training points from the solution.\n",
    "\n",
    ">Next, we will train a PINN to extrapolate the full solution outside of these training points by penalising the underlying differential equation in its loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3d0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch # pip install torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac19c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gif_PIL(outfile, files, fps=5, loop=0):\n",
    "    \"Helper function for saving GIFs\"\n",
    "    imgs = [Image.open(file) for file in files]\n",
    "    imgs[0].save(fp=outfile, format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e483a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oscillator(d, w0, x):\n",
    "    \"\"\"Defines the analytical solution to the 1D underdamped harmonic oscillator problem. \n",
    "    Equations taken from: https://beltoforion.de/en/harmonic_oscillator/\"\"\"\n",
    "    assert d < w0\n",
    "    w = np.sqrt(w0**2-d**2)\n",
    "    phi = np.arctan(-d/w)\n",
    "    A = 1/(2*np.cos(phi))\n",
    "    cos = torch.cos(phi+w*x)\n",
    "    sin = torch.sin(phi+w*x)\n",
    "    exp = torch.exp(-d*x)\n",
    "    y  = exp*2*A*cos\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfb921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    \"Defines a connected network\"\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(*[\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee01e6",
   "metadata": {},
   "source": [
    "## Generate training data\n",
    "\n",
    "> First, we generate some training data from a small part of the true analytical solution.\n",
    "\n",
    "For this problem, we use $\\delta=2$, $\\omega_0=20$, and try to learn the solution over the domain $x\\in [0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fda9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1]) torch.Size([500, 1])\n",
      "torch.Size([10, 1]) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "d, w0 = 2, 20\n",
    "\n",
    "x = torch.linspace(0,1,500).view(-1,1)\n",
    "y = oscillator(d, w0, x).view(-1,1)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# slice out a small number of points from the LHS of the domain\n",
    "x_data = x[0:200:20]\n",
    "y_data = y[0:200:20]\n",
    "print(x_data.shape, y_data.shape)\n",
    "\n",
    "#plt.figure()\n",
    "plt.plot(x, y, label=\"Exact solution\")\n",
    "#plt.scatter(x_data, y_data, color=\"tab:orange\", label=\"Training data\")\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "d, w0 = 2, 20\n",
    "\n",
    "# get the analytical solution over the full domain\n",
    "x = torch.linspace(0,1,500).view(-1,1)\n",
    "y = oscillator(d, w0, x).view(-1,1)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# slice out a small number of points from the LHS of the domain\n",
    "x_data = x[0:200:20]\n",
    "y_data = y[0:200:20]\n",
    "print(x_data.shape, y_data.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, label=\"Exact solution\")\n",
    "plt.scatter(x_data, y_data, color=\"tab:orange\", label=\"Training data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8cd505",
   "metadata": {},
   "source": [
    "## Normal neural network\n",
    "\n",
    "> Next, we train a standard neural network (fully connected network) to fit these training points.\n",
    "\n",
    ">We find that the network is able to fit the solution very closely in the vicinity of the training points, but does not learn an accurate solution outside of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847195e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_result(x,y,x_data,y_data,yh,xp=None):\n",
    "    \"Pretty plot training results\"\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(x,y, color=\"grey\", linewidth=2, alpha=0.8, label=\"Exact solution\")\n",
    "    plt.plot(x,yh, color=\"tab:blue\", linewidth=4, alpha=0.8, label=\"Neural network prediction\")\n",
    "    plt.scatter(x_data, y_data, s=60, color=\"tab:orange\", alpha=0.4, label='Training data')\n",
    "    if xp is not None:\n",
    "        plt.scatter(xp, -0*torch.ones_like(xp), s=60, color=\"tab:green\", alpha=0.4, \n",
    "                    label='Physics loss training locations')\n",
    "    l = plt.legend(loc=(1.01,0.34), frameon=False, fontsize=\"large\")\n",
    "    plt.setp(l.get_texts(), color=\"k\")\n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.text(1.065,0.7,\"Training step: %i\"%(i+1),fontsize=\"xx-large\",color=\"k\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    \n",
    "# train standard neural network to fit training data\n",
    "torch.manual_seed(123)\n",
    "model = FCN(1,1,32,3)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "files = []\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    yh = model(x_data)\n",
    "    loss = torch.mean((yh-y_data)**2)# use mean squared error\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (i+1) % 10 == 0: \n",
    "        \n",
    "        yh = model(x).detach()\n",
    "        \n",
    "        plot_result(x,y,x_data,y_data,yh)\n",
    "        \n",
    "        file = \"plots/nn_%.8i.png\"%(i+1)\n",
    "        plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "        files.append(file)\n",
    "    \n",
    "        if (i+1) % 500 == 0: plt.show()\n",
    "        else: plt.close(\"all\")\n",
    "            \n",
    "save_gif_PIL(\"nn.gif\", files, fps=20, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d57ca",
   "metadata": {},
   "source": [
    "## PINN\n",
    "\n",
    "> Finally, we add the underlying differential equation (\"physics loss\") to the loss function. \n",
    "\n",
    "The physics loss aims to ensure that the learned solution is consistent with the underlying differential equation. This is done by penalising the residual of the differential equation over a set of locations sampled from the domain.\n",
    "\n",
    "Here we evaluate the physics loss at 30 points uniformly spaced over the problem domain $([0,1])$. We can calculate the derivatives of the network solution with respect to its input variable at these points using `pytorch`'s autodifferentiation features, and can then easily compute the residual of the differential equation using these quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc42d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)# sample locations over the problem domain\n",
    "mu, k = 2*d, w0**2\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = FCN(1,1,32,3)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "files = []\n",
    "for i in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute the \"data loss\"\n",
    "    yh = model(x_data)\n",
    "    loss1 = torch.mean((yh-y_data)**2)# use mean squared error\n",
    "    \n",
    "    # compute the \"physics loss\"\n",
    "    yhp = model(x_physics)\n",
    "    dx  = torch.autograd.grad(yhp, x_physics, torch.ones_like(yhp), create_graph=True)[0]# computes dy/dx\n",
    "    dx2 = torch.autograd.grad(dx,  x_physics, torch.ones_like(dx),  create_graph=True)[0]# computes d^2y/dx^2\n",
    "    physics = dx2 + mu*dx + k*yhp# computes the residual of the 1D harmonic oscillator differential equation\n",
    "    loss2 = (1e-4)*torch.mean(physics**2)\n",
    "    \n",
    "    # backpropagate joint loss\n",
    "    loss = loss1 + loss2# add two loss terms together\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (i+1) % 150 == 0: \n",
    "        \n",
    "        yh = model(x).detach()\n",
    "        xp = x_physics.detach()\n",
    "        \n",
    "        plot_result(x,y,x_data,y_data,yh,xp)\n",
    "        \n",
    "        file = \"plots/pinn_%.8i.png\"%(i+1)\n",
    "        plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "        files.append(file)\n",
    "        \n",
    "        if (i+1) % 6000 == 0: plt.show()\n",
    "        else: plt.close(\"all\")\n",
    "            \n",
    "save_gif_PIL(\"pinn.gif\", files, fps=20, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026fd49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
